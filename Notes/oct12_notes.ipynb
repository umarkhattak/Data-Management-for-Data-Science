{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='brown'>Processing Datasets: CSV and JSON</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: UCI Iris Dataset - CSV File\n",
    "\n",
    "This file (*iris-messy.csv*) has 5 columns (fields): sepal_length, sepal_width, petal_length, petal_width, iris_type\n",
    "\n",
    "I have deliberately introduced errors in the dataset so you get a feel for what kinds of errors you might generally expect, and how to take corrective action. \n",
    "\n",
    "These are some of the kinds of errors you might see in datasets in general:\n",
    "- Too many fields\n",
    "- Too few fields\n",
    "- Missing fields\n",
    "- Unknown value (e.g. ?,NA instead of actual value)\n",
    "- Non-numeric value when numeric is expected\n",
    "\n",
    "Other errors are possible (such as outlier values), and we will see/handle some of then when we study the Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Make sure there are exactly 5 fields in each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009 >>> ['4.4', '2', '9', '1.4', '0.2', 'Iris-setosa']\n",
      "064 >>> ['6.1', '4.7', '1.4', 'Iris-versicolor']\n",
      "078 >>> ['6.7', '3.0', '4.5', '1.7', '6.5', 'Iris-versicolor']\n",
      "103 >>> ['7', '1', '3.0', '5.9', '2.1', 'Iris-virginica']\n",
      "113 >>> ['6.8', '3.0', '5.5', '2.1']\n",
      "152 >>> []\n"
     ]
    }
   ],
   "source": [
    "with open('iris-messy.csv') as irisfile:\n",
    "    reader = csv.reader(irisfile)\n",
    "    next(reader)  # skip first line of field names\n",
    "    for num,row in enumerate(reader):  # row will be a list of all column values\n",
    "        if len(row) != 5:  # lines that have too many or too few fields\n",
    "            print(f'{(num+1):03} >>> {row}')  # notice the padding with leading zeros for row number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Make sure all fields except last are real numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 009: Too few or too many fields\n",
      "\t ['4.4', '2', '9', '1.4', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 013: Non-numeric value\n",
      "\t ['4.8', 'N/A', '1.4', '0.1', 'Iris-setosa'] \n",
      "\n",
      "Row 035: Non-numeric value\n",
      "\t ['4.9', '3.1', 'n/a', '0.1', 'Iris-setosa'] \n",
      "\n",
      "Row 036: Non-numeric value\n",
      "\t ['5.0', 'na', '1.2', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 043: Non-numeric value\n",
      "\t ['?', '3.2', '1.3', '0.2', 'Iris-setosa'] \n",
      "\n",
      "Row 064: Too few or too many fields\n",
      "\t ['6.1', '4.7', '1.4', 'Iris-versicolor'] \n",
      "\n",
      "Row 070: Non-numeric value\n",
      "\t ['5.6', '2.5', '3.9', 'NA', 'Iris-versicolor'] \n",
      "\n",
      "Row 077: Non-numeric value\n",
      "\t ['6.8', '2.8', '?', '1.4', 'Iris-versicolor'] \n",
      "\n",
      "Row 078: Too few or too many fields\n",
      "\t ['6.7', '3.0', '4.5', '1.7', '6.5', 'Iris-versicolor'] \n",
      "\n",
      "Row 103: Too few or too many fields\n",
      "\t ['7', '1', '3.0', '5.9', '2.1', 'Iris-virginica'] \n",
      "\n",
      "Row 113: Too few or too many fields\n",
      "\t ['6.8', '3.0', '5.5', '2.1'] \n",
      "\n",
      "Row 127: Non-numeric value\n",
      "\t ['6.2', '2.8', '4x8', '1.8', 'Iris-virginica'] \n",
      "\n",
      "Row 137: Non-numeric value\n",
      "\t ['6.3', '3.4', '5.6', '?', 'Iris-virginica'] \n",
      "\n",
      "Row 148: Non-numeric value\n",
      "\t ['', '3.0', '5.2', '2.0', 'Iris-virginica'] \n",
      "\n",
      "Row 152: Too few or too many fields\n",
      "\t [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure all fields except last are real numbers\n",
    "with open('iris-messy.csv') as irisfile:\n",
    "    reader = csv.reader(irisfile)\n",
    "    next(reader)  # skip first line of field names\n",
    "    for num,row in enumerate(reader):\n",
    "        if len(row) != 5:  # lines that have too many or too few fields\n",
    "            print(f'Row {(num+1):03}: Too few or too many fields')\n",
    "            print('\\t',row,'\\n')\n",
    "        else:\n",
    "            for val in row[:-1]:  # skip last field\n",
    "                try:\n",
    "                    float(val)\n",
    "                except:\n",
    "                    print(f'Row {(num+1):03}: Non-numeric value')\n",
    "                    print('\\t',row,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Finalize by writing out acceptable lines:**\n",
    "- Skip lines that have too few or too many fields\n",
    "- Replace non-numeric field with NA (standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iris-better.csv','w') as outfile:\n",
    "    with open('iris-messy.csv') as irisfile:\n",
    "        \n",
    "        reader = csv.reader(irisfile)\n",
    "        \n",
    "        row = next(reader)  # first line of field names\n",
    "        outfile.write(','.join(row))\n",
    "        outfile.write('\\n')\n",
    "    \n",
    "        for num,row in enumerate(reader):\n",
    "            if len(row) != 5:  # lines that have too many or too few fields\n",
    "                continue\n",
    "            else:\n",
    "                outrow = []\n",
    "                for val in row[:-1]:  # skip last field\n",
    "                    try:\n",
    "                        float(val)\n",
    "                        outrow.append(val)\n",
    "                    except:\n",
    "                        outrow.append('NA')\n",
    "                outrow.append(row[-1])\n",
    "                outfile.write(','.join(outrow))\n",
    "                outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, you can use a CSV writer to write out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('iris-better.csv','w',newline='') as csvfile:  # note the newline='' parameter\n",
    "    writer = csv.writer(csvfile, delimiter=',')  # set outfile field delimiter to comma\n",
    "   \n",
    "    with open('iris-messy.csv') as irisfile:\n",
    "        \n",
    "        reader = csv.reader(irisfile)\n",
    "        \n",
    "        row = next(reader)  # first line of field names\n",
    "        writer.writerow(row)  # use writerow method of writer with list of fields as param\n",
    "    \n",
    "        for num,row in enumerate(reader):\n",
    "            if len(row) != 5:  # lines that have too many or too few fields\n",
    "                continue\n",
    "            else:\n",
    "                outrow = []\n",
    "                for val in row[:-1]:  # skip last field\n",
    "                    try:\n",
    "                        float(val)\n",
    "                        outrow.append(val)\n",
    "                    except:\n",
    "                        outrow.append('NA')\n",
    "                outrow.append(row[-1])\n",
    "                writer.writerow(outrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: Processing Auto-mpg CSV file Using DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mpg', '18.0'), ('cylinders', '8.'), ('displacement', '307.0'), ('horsepower', '130.0'), ('weight', '3504.'), ('acceleration', '12.0'), ('model year', '70.'), ('origin', '1.'), ('car name', 'chevrolet chevelle malibu')])\n",
      "OrderedDict([('mpg', '15.0'), ('cylinders', '8.'), ('displacement', '350.0'), ('horsepower', '165.0'), ('weight', '3693.'), ('acceleration', '11.5'), ('model year', '70.'), ('origin', '1.'), ('car name', 'buick skylark 320')])\n",
      "OrderedDict([('mpg', '18.0'), ('cylinders', '8.'), ('displacement', '318.0'), ('horsepower', '150.0'), ('weight', '3436.'), ('acceleration', '11.0'), ('model year', '70.'), ('origin', '1.'), ('car name', 'plymouth satellite')])\n",
      "OrderedDict([('mpg', '16.0'), ('cylinders', '8.'), ('displacement', '304.0'), ('horsepower', '150.0'), ('weight', '3433.'), ('acceleration', '12.0'), ('model year', '70.'), ('origin', '1.'), ('car name', 'amc rebel sst')])\n",
      "OrderedDict([('mpg', '17.0'), ('cylinders', '8.'), ('displacement', '302.0'), ('horsepower', '140.0'), ('weight', '3449.'), ('acceleration', '10.5'), ('model year', '70.'), ('origin', '1.'), ('car name', 'ford torino')])\n"
     ]
    }
   ],
   "source": [
    "# using DictReader on csv\n",
    "reader = csv.DictReader(open('auto_mpg_original.csv'))\n",
    "for index,row in enumerate(reader):\n",
    "    print(row)\n",
    "    if index > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
      "mpg,cylinders,displacement,horsepower,weight,acceleration,model year,origin,car name\n",
      "NA,4.,133.0,115.0,3090.,17.5,70.,2.,\"citroen ds-21 pallas\"\n",
      "NA,8.,350.0,165.0,4142.,11.5,70.,1.,\"chevrolet chevelle concours (sw)\"\n",
      "NA,8.,351.0,153.0,4034.,11.0,70.,1.,\"ford torino (sw)\"\n",
      "NA,8.,383.0,175.0,4166.,10.5,70.,1.,\"plymouth satellite (sw)\"\n",
      "NA,8.,360.0,175.0,3850.,11.0,70.,1.,\"amc rebel sst (sw)\"\n",
      "NA,8.,302.0,140.0,3353.,8.0,70.,1.,\"ford mustang boss 302\"\n",
      "25.0,4.,98.00,NA,2046.,19.0,71.,1.,\"ford pinto\"\n",
      "NA,4.,97.00,48.00,1978.,20.0,71.,2.,\"volkswagen super beetle 117\"\n",
      "21.0,6.,200.0,NA,2875.,17.0,74.,1.,\"ford maverick\"\n",
      "40.9,4.,85.00,NA,1835.,17.3,80.,2.,\"renault lecar deluxe\"\n",
      "23.6,4.,140.0,NA,2905.,14.3,80.,1.,\"ford mustang cobra\"\n",
      "34.5,4.,100.0,NA,2320.,15.8,81.,2.,\"renault 18i\"\n",
      "NA,4.,121.0,110.0,2800.,15.4,81.,2.,\"saab 900s\"\n",
      "23.0,4.,151.0,NA,3035.,20.5,82.,1.,\"amc concord dl\"\n"
     ]
    }
   ],
   "source": [
    "# using fieldnames and values methods\n",
    "\n",
    "reader = csv.DictReader(open('auto_mpg_original.csv'))\n",
    "print(reader.fieldnames)\n",
    "print(','.join(reader.fieldnames))\n",
    "for index,row in enumerate(reader):\n",
    "    values = list(row.values())  # need to cast row.values() to list\n",
    "    if 'NA' in values:\n",
    "        values[-1] = '\"' + values[-1] + '\"'\n",
    "        print(','.join(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing out a cleaned up version into a CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.DictReader(open('auto_mpg_original.csv')) # input, has a bunch of NAs for values\n",
    "csvfile = open('auto_mpg.csv','w') # output, delete lines with NA for any value\n",
    "\n",
    "csvfile.write(','.join(reader.fieldnames)+'\\n')  # header line with field names    \n",
    "for row in reader:\n",
    "    if 'NA' in row.values():\n",
    "        continue\n",
    "    values = list(row.values())\n",
    "    values[-1] = '\"' + values[-1] + '\"'\n",
    "    csvfile.write(','.join(values)+'\\n')\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, you can use a CSV DictWriter writer to write out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auto_mpg_original.csv') as infile: \n",
    "    reader = csv.DictReader(infile)\n",
    "    \n",
    "    with open('auto_mpg.csv','w',newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile,fieldnames=reader.fieldnames,delimiter=' ')\n",
    "\n",
    "        writer.writeheader()   \n",
    "        for row in reader:\n",
    "            if 'NA' in row.values():\n",
    "                continue\n",
    "            writer.writerow(row)  # since "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: Converting a tab-delimited text file without headers to CSV file with headers\n",
    "\n",
    "This example was not covered in lecture, please review it - most of the code structure is\n",
    "as in previous examples, the new thing is the introduction of fieldnames externally instead\n",
    "of getting it from an input csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/29/2020 : USA : 4.56\n",
      "7/29/2020 : Brazil : 2.55\n",
      "7/29/2020 : India : 1.59\n",
      "7/30/2020 : USA : 4.63\n",
      "7/30/2020 : Brazil : 2.61\n",
      "7/30/2020 : India : 1.63\n"
     ]
    }
   ],
   "source": [
    "# this file is tab-delimited and does not have a header row with field nams\n",
    "with open('coronatab.txt') as covfile:\n",
    "    reader = csv.reader(covfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        country = row[1]\n",
    "        cases = float(row[2])\n",
    "        print(date,':',country,':',cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can write out the tab-delimited file as a comma-separated file with headers\n",
    "columns = ['Date','Country','Cases']\n",
    "with open('corona.csv','w') as covout:\n",
    "    csv_writer = csv.writer(covout) # comma is default delimiter\n",
    "    csv_writer.writerow(columns)\n",
    "    with open('coronatab.txt') as covfile:\n",
    "        reader = csv.reader(covfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            date = row[0]\n",
    "            country = row[1]\n",
    "            cases = row[2]\n",
    "            csv_writer.writerow([date,country,cases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, you can use a DictReader/DictWriter by supplying field names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coronatab.txt') as covfile:\n",
    "    reader = csv.DictReader(covfile, delimiter='\\t', fieldnames=['Date','Country','Cases'])\n",
    "    with open('corona.csv','w',newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile,fieldnames=reader.fieldnames)\n",
    "        writer.writeheader() \n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"brown\">Working with JSON - JavaScript Object Notation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading a JSON-formatted string into a JSON object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hill center': 'Busch', 'AB': 'College Ave'}\n"
     ]
    }
   ],
   "source": [
    "json1 = '{\"hill center\":\"Busch\", \"AB\":\"College Ave\"}'   # a string containing dictionary formatted data\n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-02721859ae17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjson1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"hill center\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Busch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"College Ave\"\u001b[0m\u001b[0;34m}\u001b[0m   \u001b[0;31m# beware, the whole thing must be a string!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# load this into Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n\u001b[0m\u001b[1;32m    342\u001b[0m                             f'not {s.__class__.__name__}')\n\u001b[1;32m    343\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "json1 = {\"hill center\":\"Busch\", \"AB\":\"College Ave\"}   # beware, the whole thing must be a string!\n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keys are required to be strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9e400efb8782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjson1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{2:\"Busch\", 1:\"College Ave\"}'\u001b[0m   \u001b[0;31m# keys MUST be strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# load this into Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "json1 = '{2:\"Busch\", 1:\"College Ave\"}'  \n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But values are not required to be strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'John': 12, 'Jane': 25}\n"
     ]
    }
   ],
   "source": [
    "json1 = '{\"John\":12, \"Jane\":25}'   # but values need not be strings\n",
    "# load this into Python\n",
    "dict1 = json.loads(json1)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30, 'city': 'New York'}\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "x =  '{ \"name\":\"John\", \"age\":30, \"city\":\"New York\"}'\n",
    "y = json.loads(x)\n",
    "print(y)\n",
    "print(y[\"age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key strings are required to be double-quoted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-00ced0ad4c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# a string MUST be double-quoted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"{ 'name':'John', 'age':30, 'city':'New York'}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "# a string MUST be double-quoted\n",
    "x =  \"{ 'name':'John', 'age':30, 'city':'New York'}\"\n",
    "y = json.loads(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dumping dictonary to JSON-formatted string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Jane\", \"age\": 25, \"city\": \"Chicago\"}\n"
     ]
    }
   ],
   "source": [
    "dat_dict = { 'name' : 'Jane', 'age' : 25, 'city' : 'Chicago'}\n",
    "dat_str = json.dumps(dat_dict)\n",
    "print(dat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'busch', 1: 'college ave'}\n"
     ]
    }
   ],
   "source": [
    "# a dictionary with integers for keys\n",
    "dict2 = {2: 'busch', 1: 'college ave'}\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"2\": \"busch\", \"1\": \"college ave\"}\n"
     ]
    }
   ],
   "source": [
    "# dump to string \n",
    "dict2_str = json.dumps(dict2)\n",
    "print(dict2_str)   # integer keys converted to strings, single-quotes strings are double-quoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': 'busch', '1': 'college ave'}\n"
     ]
    }
   ],
   "source": [
    "dict2_new = json.loads(dict2_str)\n",
    "print(dict2_new)   \n",
    "# BEWARE: when loaded back, dict keys change to strings\n",
    "# so dict2 is NOT the same as dict2_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using arrays as values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "json3 = '{\"name\": \"Anika\", \"quiz_scores\":[38,40,36,40,32]}'\n",
    "dict3 = json.loads(json3)\n",
    "print(dict3['quiz_scores'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quiz_scores': [{'name': 'Anika', 'scores': [38, 40, 36, 40, 32]}, {'name': 'Amir', 'scores': [36, 38, 40, 30, 34]}]}\n"
     ]
    }
   ],
   "source": [
    "# 2 students with quiz scores, value is array of dictionaries\n",
    "json4 = '{\"quiz_scores\" : [{\"name\": \"Anika\", \"scores\":[38,40,36,40,32]}, {\"name\": \"Amir\", \"scores\":[36,38,40,30,34]}]}'\n",
    "dict4 = json.loads(json4)\n",
    "print(dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amir\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(dict4['quiz_scores'][1]['name'])  # name of second item in quiz_scores value array\n",
    "print(dict4['quiz_scores'][0]['scores'][3])  # 4th score of first item in quiz_scores value array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
